{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Viny2030/tensorflow/blob/main/PyTorch_for_Beginners.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqhklyZ_zeFa"
      },
      "source": [
        "# PyTorch for Beginners\n",
        "\n",
        "In this notebook, we will try out the codes we used in the [PyTorch for Beginners](https://www.learnopencv.com/pytorch-for-beginners-basics/) blog.\n",
        "\n",
        "\n",
        " <img src='https://opencv.org/wp-content/uploads/2023/05/c3_w1_pytorch_basics_cover.jpg' width=700 align='center'><br/>\n",
        "\n",
        "Let's start off by installing PyTorch.\n",
        "\n",
        "\n",
        "\n",
        "## Table of Contents\n",
        "* [1. Converting Image to tensors](#1.-Converting-Image-to-tensors)\n",
        "* [2. Introduction to Tensors and its Operations](#2.-Introduction-to-Tensors-and-its-Operations)\n",
        "\n",
        "* [3. Conclusion](#5.-Conclusion)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "TfSSU72-wLrw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lu6Nap-AzvIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa102b7-ff9a-4f75-9f42-cbc7f1b63c3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# Use this if you have conda installed\n",
        "# !conda install -c pytorch pytorch\n",
        "\n",
        "# Use this if you are on Google Colab\n",
        "# or don't have conda installed\n",
        "!pip3 install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download some digit images from MNIST dataset\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_0.jpg\" -O \"mnist_0.jpg\"\n",
        "!wget -q \"https://learnopencv.com/wp-content/uploads/2024/07/mnist_1.jpg\" -O \"mnist_1.jpg\""
      ],
      "metadata": {
        "id": "-PfSnTVfcwMO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXlDsyiT0QkG"
      },
      "source": [
        "Let's verify that we have the latest PyTorch version (1.1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XTu5IogH3Xgq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4peb4GAdVnVI",
        "outputId": "8de0ece4-54eb-4646-c9ab-e8730ec6cf9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version : 2.5.1+cu124\n"
          ]
        }
      ],
      "source": [
        "print(\"torch version : {}\".format(torch.__version__))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Converting Images to Batched tensors\n",
        "\n",
        "An image is made up of pixel arrays that represent the intensity of pixels in grayscale or the color values in RGB format. When working with deep learning models, it's often necessary to convert these images into tensors, which are the primary data structures used in PyTorch for handling and processing data.\n",
        "\n",
        "* **Tensors**: In PyTorch, tensors are multi-dimensional arrays similar to NumPy arrays, but with additional capabilities for GPU acceleration and automatic differentiation. Tensors are the fundamental building blocks for representing data and parameters in neural networks.\n",
        "* **Batches**: Batching is a technique where multiple data samples (images, in this case) are grouped together into a single tensor. This allows efficient processing of multiple samples simultaneously, to take advantage of the parallel processing capabilities of modern hardware.\n"
      ],
      "metadata": {
        "id": "Lgbl_exQeSBG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conversión de imágenes en tensores por lotes**\n",
        "Una imagen se compone de matrices de píxeles que representan la intensidad de los píxeles en escala de grises o los valores de color en formato RGB. Al trabajar con modelos de aprendizaje profundo, a menudo es necesario convertir estas imágenes en tensores, que son las principales estructuras de datos utilizadas en PyTorch para el manejo y procesamiento de datos.\n",
        "\n",
        "Tensores: En PyTorch, los tensores son matrices multidimensionales similares a las matrices de NumPy, pero con capacidades adicionales de aceleración por GPU y diferenciación automática. Los tensores son los componentes fundamentales para la representación de datos y parámetros en redes neuronales.\n",
        "Lotes: La agrupación por lotes es una técnica en la que múltiples muestras de datos (imágenes, en este caso) se agrupan en un único tensor. Esto permite el procesamiento eficiente de múltiples muestras simultáneamente, aprovechando las capacidades de procesamiento paralelo del hardware moderno."
      ],
      "metadata": {
        "id": "SuW81Se78QAw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following block, we will see an example of converting two MNIST images into a single batched tensor of shape `[2,3,28,28]`"
      ],
      "metadata": {
        "id": "Z12KLdsrp8xR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "digit_0_array_og = cv2.imread(\"mnist_0.jpg\")\n",
        "digit_1_array_og = cv2.imread(\"mnist_1.jpg\")\n",
        "\n",
        "digit_0_array_gray = cv2.imread(\"mnist_0.jpg\",cv2.IMREAD_GRAYSCALE )\n",
        "digit_1_array_gray = cv2.imread(\"mnist_1.jpg\",cv2.IMREAD_GRAYSCALE )\n",
        "\n",
        "# Visualize the image\n",
        "\n",
        "fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
        "\n",
        "\n",
        "axs[0].imshow(digit_0_array_og, cmap='gray',interpolation='none')\n",
        "axs[0].set_title(\"Digit 0 Image\")\n",
        "axs[0].axis('off')\n",
        "\n",
        "axs[1].imshow(digit_1_array_og, cmap=\"gray\", interpolation = 'none')\n",
        "axs[1].set_title(\"Digit 1 Image\")\n",
        "axs[1].axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "kVI3AFLLbS3E",
        "outputId": "d3e8a152-682d-44e2-fc35-7a11cc1b4082"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Numpy array with three channels\n",
        "print(\"Image array shape: \",digit_0_array_og.shape)\n",
        "print(f\"Min pixel value:{np.min(digit_0_array_og)} ; Max pixel value : {np.max(digit_0_array_og)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttB6pUHUdIm4",
        "outputId": "cf435c8a-8543-4c63-c211-369666fa8342"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image array shape:  (28, 28, 3)\n",
            "Min pixel value:0 ; Max pixel value : 255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We will have a look at 28x28 single channel image's pixel values\n",
        "digit_0_array_gray"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "oUCmiJ7_nwtw",
        "outputId": "f436a1b5-8569-49ed-b569-dda0712f1f1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
              "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
              "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
              "          0,   0],\n",
              "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
              "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
              "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
              "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
              "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
              "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
              "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
              "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
              "          1,   5],\n",
              "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
              "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
              "          0,   4],\n",
              "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
              "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
              "          0,   3],\n",
              "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
              "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
              "          0,   2],\n",
              "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
              "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
              "          0,   2],\n",
              "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
              "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
              "          0,   3],\n",
              "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
              "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
              "          0,   5],\n",
              "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
              "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
              "          0,   6],\n",
              "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
              "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
              "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
              "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
              "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
              "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
              "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
              "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
              "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-f3f69294-2914-48c0-a7c2-809affdfed90\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAB5ElEQVR4nMWSv2sUURSFv3fnvXnzdrM7cQOSZFHWWhIRywgRKxG0sbEQJGCRP8BGC7WwsQ+aXggsgpWInWJhUGsRURQSJIH8Yo3ZmezOzrXYjfgfeNvD+biccwDwhogGEUQQEKoYAPAeAEmwQGyRSKAKgEFiGwIIkUmRccTD8aFxDBIDCEAd8IEhC4DIgR2nUo9P3H2punxxGtKR5h1hDCxnX6luqm501y+AHT6SQgy1eKmj+fbbJ28Gxe+NOy4eOcFz7vWPMsuXThJP0rq9pSsjrIUKD7uarV4BAQ/nd9dmBeMAS33uo+r7GZOCwQo86rY9WISAvV8U71qAI7Jg3FX9Pm6IcCTwuMxmPUnARhFYJvJyyiK2b3oY8rAuFAUuA4RmbJwBgRJ30C+ms1QIJcBg4rLpGDAiivR7yYdPzU6vkR0meDPYOdVNyxIRC6Ih/mx+WnZjcgqtzNyo9Ac6qs0t781Tx2ISArht1eVhCKGKuadzGBxGgGZbsy/To4iEqYX8mifGAO7MM93XpSOpArWvmlIlxPiFvcN9fTo7FFOQmFub3ZXFydalBy8OMtXn9m/ZSYTMr5W5dlVVVXeu12ocO+ICNFa3eqqqv7R9unG0L8RhjUsIi+1Ortm3m5V/FvQf7g9SnKBxm+913QAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   7,   1,   0,   3,   0,  18,   0,   3,   0,\n",
              "          0,   3,   0,   0,   9,   0,   2,   0,  11,   0,   1,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   7,   0,   0,   0,   0,   0,   2,   8,   0,   4,   0,\n",
              "          0,   0,   6,   4,   0,   2,   3,   2,   0,   0,  11,   0,   0,\n",
              "          0,   0],\n",
              "       [  1,   0,   2,   6,   4,   9,   9,   0,   0,   2,   0,   3,   1,\n",
              "         15,   0,   2,  16,   0,   2,   7,   0,   0,  22,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 12,   0,   0,   8,   1,   0,   0,   0,   2,   0,   0,   0,   0,\n",
              "         14,   0,   0,   0,   7,   9,   0,   7,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   3,   5,   0,   0,   4,  16,   0,  10,  14,   6,  29,\n",
              "        122, 182, 255, 255, 152,  66,  26,   0,   0,  15,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   5,   0,   9,  12,   0,   0,   4,   0,  49, 184, 255,\n",
              "        255, 232, 255, 255, 231, 246, 227,  64,   0,   0,   4,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,  15,   0,   0,   6,   0,   0,  13,   6, 148, 241, 255, 248,\n",
              "        236, 194, 151, 192, 253, 252, 244, 231, 121,   5,   6,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   7,   0,   0,   7,   0,  51, 191, 223, 254, 247, 248, 148,\n",
              "         30,   0,   6,  24,   0,  32, 116, 235, 255, 166,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   4,   0,   0,  10,   0, 132, 246, 255, 247, 199,  77,   0,\n",
              "          0,   2,   0,   0,   7,   0,   0,  60, 238, 226,  46,   2,   0,\n",
              "          1,   5],\n",
              "       [  0,   0,   4,   0,  14,  59, 203, 255, 255, 201,  45,   1,  15,\n",
              "          0,   0,   1,   0,   4,   2,   0,   0, 137, 246, 169,   7,   0,\n",
              "          0,   4],\n",
              "       [  2,   0,   9,   0,   4, 127, 252, 252, 198,  32,   0,   0,   0,\n",
              "          5,   0,   3,   4,   0,   0,   1,   5,  78, 255, 222,  16,   1,\n",
              "          0,   3],\n",
              "       [  5,   0,   8,   0,   0, 150, 254, 247,  46,   7,   0,   8,   9,\n",
              "          0,   4,   3,   3,   0,   0,   4,   0,  19, 248, 254,  25,   4,\n",
              "          0,   2],\n",
              "       [  0,   1,   2,   0,   1, 150, 246, 255,  17,   9,   0,   4,   0,\n",
              "          0,   9,   0,   0,   0,   0,   6,   0,  46, 254, 255,  30,   5,\n",
              "          0,   2],\n",
              "       [  0,   1,   0,   0,   6, 139, 241, 251,  43,   0,  15,   6,   0,\n",
              "          9,   7,   0,   0,   0,   0,   3,  19, 120, 255, 240,  31,   5,\n",
              "          0,   3],\n",
              "       [  2,   0,   0,   2,   1, 133, 249, 197,   0,  27,   0,   0,  18,\n",
              "          0,   0,   8,   0,   7,   1,   0,   0, 153, 245, 255,  29,   3,\n",
              "          0,   5],\n",
              "       [  6,   0,   0,   4,   0, 142, 255, 156,   1,   0,   4,   0,   0,\n",
              "          6,   0,   0,   0,   3,   0,  10,  45, 245, 255, 250,  26,   2,\n",
              "          0,   6],\n",
              "       [  0,   0,   0,   0,   5, 152, 239,  63,   0,  14,   0,   4,   0,\n",
              "          1,   8,   0,   9,   0,   0,   5, 236, 255, 255, 152,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   9,  11,   0,   1, 126, 255,  59,   0,   1,   0,   5,   0,\n",
              "          1,   2,   0,   0,   0,  27, 169, 255, 247, 217,  26,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   2,   0,  25,  97, 248,  83,   7,   0,   6,   0,   1,\n",
              "          0,   0,   0,   5,  47, 171, 255, 243, 255, 148,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   0,  10,   0,   0,  13, 219, 255,  15,   0,  11,   0,   9,\n",
              "          6,   0,   7,  97, 239, 249, 243, 255, 163,  46,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [ 15,   0,   0,   2,   6,   0, 100, 232, 246, 166, 104,  24,  32,\n",
              "         72, 128, 180, 245, 247, 255, 255, 174,   4,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   8,   3,   0,   2,  63, 226, 254, 248, 255, 246, 255,\n",
              "        255, 255, 255, 255, 255, 237,  88,  13,  13,   0,  17,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   2,   0,   0,   0,   0,   0,  18, 199, 235, 250, 255, 255,\n",
              "        255, 255, 242, 255, 169,  43,  18,   0,   0,  11,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  2,   5,   0,   4,   1,   5,   8,   0,   9, 104, 169, 241, 248,\n",
              "        255, 247, 220,  95,  10,   7,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-f3f69294-2914-48c0-a7c2-809affdfed90 button').onclick = (e) => {\n",
              "        document.querySelector('#id-f3f69294-2914-48c0-a7c2-809affdfed90').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-f3f69294-2914-48c0-a7c2-809affdfed90 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Convert Numpy array to Torch tensors"
      ],
      "metadata": {
        "id": "hKA82xa7xDW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the images to PyTorch tensors and normalize\n",
        "img_tensor_0 = torch.tensor(digit_0_array_og, dtype=torch.float32) / 255.0\n",
        "img_tensor_1 = torch.tensor(digit_1_array_og, dtype=torch.float32) / 255.0\n",
        "\n",
        "print(\"Shape of Normalised Digit 0 Tensor: \", img_tensor_0.shape)\n",
        "print(f\"Normalised Min pixel value: {torch.min(img_tensor_0)} ; Normalised Max pixel value : {torch.max(img_tensor_0)}\")\n",
        "\n",
        "plt.imshow(img_tensor_0,cmap=\"gray\")\n",
        "plt.title(\"Normalised Digit 0 Image\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "X3XeGklJdz36",
        "outputId": "705c9957-1d85-4d03-9e0f-d7dfe6e4bbbb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Normalised Digit 0 Tensor:  torch.Size([28, 28, 3])\n",
            "Normalised Min pixel value: 0.0 ; Normalised Max pixel value : 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Creating Input Batch"
      ],
      "metadata": {
        "id": "K6C1MPtrgRYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_tensor = torch.stack([img_tensor_0, img_tensor_1])\n",
        "\n",
        "# In PyTorch the forward pass of input images to the model is expected to have a batch_size > 1\n",
        "print(\"Batch Tensor Shape:\", batch_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSLTIn0QgVC4",
        "outputId": "7bbda646-a90d-4991-bbed-5ee3b1d4dc16"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Tensor Shape: torch.Size([2, 28, 28, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally in PyTorch, image tensors typically follow the shape convention **[N\n",
        ",C ,H ,W]** unlike tensorflow which follows [N, H, W, C].\n",
        "\n",
        "Therefore, we need to bring the color channel to the second dimension. This can be achieved using either `torch.view()` or `torch.permute()`.\n"
      ],
      "metadata": {
        "id": "Fp_qlCZGhHSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Además, en PyTorch, los tensores de imagen suelen seguir la convención de forma [N, C, H, W], a diferencia de tensorflow, que sigue [N, H, W, C].\n",
        "\n",
        "Por lo tanto, necesitamos llevar el canal de color a la segunda dimensión. Esto se puede lograr con torch.view() o torch.permute()."
      ],
      "metadata": {
        "id": "JY17oM428ahF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_input = batch_tensor.permute(0,3,1,2)\n",
        "print(\"Batch Tensor Shape:\", batch_input.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv3D1A0fhlIR",
        "outputId": "312f1793-5ce2-4df1-c500-5a7dfb554c54"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Tensor Shape: torch.Size([2, 3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp--FrJM0eoO"
      },
      "source": [
        "# 2. Introduction to Tensors and its Operations\n",
        "\n",
        "We have seen the importance of tensors, now will understand it from ground up.\n",
        "Tensor is simply a fancy name given to matrices. If you are familiar with NumPy arrays, understanding and using PyTorch Tensors will be very easy. A scalar value is represented by a 0-dimensional Tensor. Similarly, a column/row matrix is represented using a 1-D Tensor and so on. Some examples of Tensors with different dimensions are shown for you to visualize and understand.\n",
        "\n",
        "<img src=https://learnopencv.com/wp-content/uploads/2019/05/PyTorch-Tensors.jpg width = 400 height=350>\n",
        "\n",
        "## 2.1. Construct your first Tensor\n",
        "\n",
        "Let’s see how we can create a PyTorch Tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Introducción a los tensores y sus operaciones**\n",
        "Hemos visto la importancia de los tensores; ahora los comprenderemos desde cero. Tensor es simplemente un nombre elegante para las matrices. Si está familiarizado con los arreglos de NumPy, comprender y usar los tensores de PyTorch le resultará muy fácil. Un valor escalar se representa mediante un tensor de dimensión cero. De forma similar, una matriz columna/fila se representa mediante un tensor unidimensional, y así sucesivamente. Se muestran algunos ejemplos de tensores con diferentes dimensiones para que los visualice y comprenda."
      ],
      "metadata": {
        "id": "9D7MYPcw8f9M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwnMQMkHvbV_",
        "outputId": "d901689c-db4f-407d-d65f-f518abea387d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1., 1.])\n",
            "tensor([0., 0., 0., 0., 0.])\n"
          ]
        }
      ],
      "source": [
        "# Create a Tensor with just ones in a column\n",
        "a = torch.ones(5)\n",
        "# Print the tensor we created\n",
        "print(a)\n",
        "\n",
        "# Create a Tensor with just zeros in a column\n",
        "b = torch.zeros(5)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZRb8bDz02PZ"
      },
      "source": [
        "We can similarly create Tensor with custom values as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhuPnpNh0qMj",
        "outputId": "2104d3c7-527c-43c0-ae09-856a82995009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4., 5.])\n"
          ]
        }
      ],
      "source": [
        "c = torch.tensor([1.0, 2.0, 3.0, 4.0, 5.0])\n",
        "print(c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj4kSyaR08-5"
      },
      "source": [
        "In all the above cases, we have created vectors or Tensors of dimension 1. Now, let’s create some tensors of higher dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwLThRRw05BJ",
        "outputId": "1bf2171d-77b8-472a-a6f4-0026890ef452"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.]])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ]
        }
      ],
      "source": [
        "d = torch.zeros(3,2)\n",
        "print(d)\n",
        "\n",
        "e = torch.ones(3,2)\n",
        "print(e)\n",
        "\n",
        "f = torch.tensor([[1.0, 2.0],[3.0, 4.0]])\n",
        "print(f)\n",
        "\n",
        "# 3D Tensor\n",
        "g = torch.tensor([[[1., 2.], [3., 4.]], [[5., 6.], [7., 8.]]])\n",
        "print(g)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cp28SfQ1Eb-"
      },
      "source": [
        "We can also find out the shape of a Tensor using **`.shape`** method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrUhi7Me1CaE",
        "outputId": "bc3a13bc-b3ff-43ca-df3d-caaad51022be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2])\n",
            "torch.Size([3, 2])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "print(f.shape)\n",
        "\n",
        "print(e.shape)\n",
        "\n",
        "print(g.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWHot39h1Z0X"
      },
      "source": [
        "## 2.2. Access an element in Tensor\n",
        "\n",
        "Now that we have created some tensors, let’s see how we can access an element in a Tensor. First let’s see how to do this for 1D Tensor aka vector."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Acceder a un elemento en un tensor***\n",
        "Ahora que hemos creado algunos tensores, veamos cómo acceder a un elemento en un tensor. Primero, veamos cómo hacerlo para un tensor unidimensional (también conocido como vector)."
      ],
      "metadata": {
        "id": "CRMiZsMh8mMT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HP4gzrE1K66",
        "outputId": "c748a13e-69d5-41a4-a664-9c5c03538ef6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.)\n"
          ]
        }
      ],
      "source": [
        "# Get element at index 2\n",
        "print(c[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gqFHFCV1k3H"
      },
      "source": [
        "What about 2D or 3D Tensor? Recall what we mentioned about **dimension of a tensor**.\n",
        "\n",
        "To access one particular element in a tensor, we will need to specify indices equal to the dimension of the tensor. That’s why for tensor **`c`** we only had to specify one index."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué ocurre con los tensores 2D o 3D? Recordemos lo que mencionamos sobre la dimensión de un tensor.\n",
        "\n",
        "Para acceder a un elemento específico de un tensor, necesitamos especificar índices iguales a la dimensión del tensor. Por eso, para el tensor c, solo tuvimos que especificar un índice."
      ],
      "metadata": {
        "id": "GYNWBevm8x67"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFR280DU1fJr",
        "outputId": "56ed6212-cc31-4d6a-aa35-96664bbb33ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.)\n",
            "tensor(3.)\n",
            "tensor(5.)\n",
            "tensor(5.)\n"
          ]
        }
      ],
      "source": [
        "# All indices starting from 0\n",
        "\n",
        "# Get element at row 1, column 0\n",
        "print(f[1,0])\n",
        "\n",
        "# We can also use the following\n",
        "print(f[1][0])\n",
        "\n",
        "# Similarly for 3D Tensor\n",
        "print(g[1,0,0])\n",
        "print(g[1][0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD0vwWDG1xr4"
      },
      "source": [
        "But what if you wanted to access one entire row in a 2D Tensor?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XB_p7OUz1u9p",
        "outputId": "ab88c65f-d778-4ca2-d03b-aad74b97d7e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]])\n",
            "tensor([2., 3.])\n",
            "tensor([1., 2., 3., 4.])\n",
            "tensor([1., 2.])\n",
            "tensor([2., 4.])\n"
          ]
        }
      ],
      "source": [
        "# All elements\n",
        "print(f[:])\n",
        "\n",
        "# All elements from index 1 to 2 (excluding element 3)\n",
        "print(c[1:3])\n",
        "\n",
        "# All elements till index 4 (exclusive)\n",
        "print(c[:4])\n",
        "\n",
        "# First row\n",
        "print(f[0, :])\n",
        "\n",
        "# Second column\n",
        "print(f[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxO2VoJv12Hh"
      },
      "source": [
        "## 2.3. Specify data type of elements\n",
        "\n",
        "Whenever we create a tensor, PyTorch decides the data type of the elements of the tensor such that the data type can cover all the elements of the tensor. We can override this by specifying the data type while creating the tensor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.3. Especificar el tipo de datos de los elementos\n",
        "Al crear un tensor, PyTorch determina el tipo de datos de sus elementos, de modo que este pueda abarcar todos sus elementos. Podemos sobrescribir esta configuración especificando el tipo de datos al crear el tensor."
      ],
      "metadata": {
        "id": "i7UGeT7Z9DXU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AyDrCBS1z_x",
        "outputId": "c4a8d78c-8917-454d-d072-64e3354847d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.int64\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n"
          ]
        }
      ],
      "source": [
        "int_tensor = torch.tensor([[1,2,3],[4,5,6]])\n",
        "print(int_tensor.dtype)\n",
        "\n",
        "# What if we changed any one element to floating point number?\n",
        "int_tensor = torch.tensor([[1,2,3],[4.,5,6]])\n",
        "print(int_tensor.dtype)\n",
        "print(int_tensor)\n",
        "\n",
        "# This can be overridden as follows\n",
        "float_tensor = torch.tensor([[1, 2, 3],[4., 5, 6]])\n",
        "int_tensor = float_tensor.type(torch.int64)\n",
        "print(int_tensor.dtype)\n",
        "print(int_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwxIIWEF2Ea8"
      },
      "source": [
        "## 2.4. Tensor to/from NumPy Array\n",
        "\n",
        "We have mentioned several times that PyTorch Tensors and NumPy arrays are pretty similar. This of course demands the question if it’s possible to convert one data structure into another. Let’s see how we can do this."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.4. Tensor a/desde un array NumPy**\n",
        "Hemos mencionado varias veces que los tensores de PyTorch y los arrays NumPy son bastante similares. Esto, por supuesto, nos lleva a preguntarnos si es posible convertir una estructura de datos en otra. Veamos cómo podemos hacerlo."
      ],
      "metadata": {
        "id": "czA-DbO59H7f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7AC_jpn2Cd6",
        "outputId": "b76c93ed-32a7-4928-ae80-6be4a2d569c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]]\n",
            "tensor([[8, 7, 6, 5],\n",
            "        [4, 3, 2, 1]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor to Array\n",
        "f_numpy = f.numpy()\n",
        "print(f_numpy)\n",
        "\n",
        "# Array to Tensor\n",
        "h = np.array([[8,7,6,5],[4,3,2,1]])\n",
        "h_tensor = torch.from_numpy(h)\n",
        "print(h_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBlMxo7j2NNH"
      },
      "source": [
        "## 2.5. Arithmetic Operations on Tensors\n",
        "\n",
        "Now it’s time for the next step. Let’s see how we can perform arithmetic operations on PyTorch tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.5. Operaciones aritméticas con tensores\n",
        "Ahora es el siguiente paso. Veamos cómo podemos realizar operaciones aritméticas con tensores de PyTorch."
      ],
      "metadata": {
        "id": "CWEp9lQ-9NDL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJGjZc212K74",
        "outputId": "333686b7-f164-490c-b436-7da927faa15a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  4,  0],\n",
            "        [ 8,  0, 12]])\n",
            "tensor([[ 0,  4,  0],\n",
            "        [ 8,  0, 12]])\n",
            "tensor([[ 2,  0,  6],\n",
            "        [ 0, 10,  0]])\n",
            "tensor([[ 2,  0,  6],\n",
            "        [ 0, 10,  0]])\n",
            "tensor([[ 2,  4,  6],\n",
            "        [ 8, 10, 12]])\n",
            "tensor([[ -1,   4,  -9],\n",
            "        [ 16, -25,  36]])\n",
            "tensor([[22, 28],\n",
            "        [49, 64]])\n",
            "tensor([[0.5000, 1.0000, 1.5000],\n",
            "        [2.0000, 2.5000, 3.0000]])\n",
            "tensor([[-1.,  1., -1.],\n",
            "        [ 1., -1.,  1.]])\n"
          ]
        }
      ],
      "source": [
        "# Create tensor\n",
        "tensor1 = torch.tensor([[1,2,3],[4,5,6]])\n",
        "tensor2 = torch.tensor([[-1,2,-3],[4,-5,6]])\n",
        "\n",
        "# Addition\n",
        "print(tensor1+tensor2)\n",
        "# We can also use\n",
        "print(torch.add(tensor1,tensor2))\n",
        "\n",
        "# Subtraction\n",
        "print(tensor1-tensor2)\n",
        "# We can also use\n",
        "print(torch.sub(tensor1,tensor2))\n",
        "\n",
        "# Multiplication\n",
        "# Tensor with Scalar\n",
        "print(tensor1 * 2)\n",
        "\n",
        "# Tensor with another tensor\n",
        "# Elementwise Multiplication\n",
        "print(tensor1 * tensor2)\n",
        "\n",
        "# Matrix multiplication\n",
        "tensor3 = torch.tensor([[1,2],[3,4],[5,6]])\n",
        "print(torch.mm(tensor1,tensor3))\n",
        "\n",
        "# Division\n",
        "# Tensor with scalar\n",
        "print(tensor1/2)\n",
        "\n",
        "# Tensor with another tensor\n",
        "# Elementwise division\n",
        "print(tensor1/tensor2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6. Broadcasting"
      ],
      "metadata": {
        "id": "n-wQZvbukBRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "   - `a` is a 1-dimensional tensor with shape \\([ 3 ]\\).\n",
        "   - `b` is a scalar tensor with shape \\([ 1 ]\\).\n",
        "   - When adding `a` and `b`, PyTorch broadcasts `b` to match the shape of `a`, resulting in \\([ 1 + 4, 2 + 4, 3 + 4 ]\\).\n"
      ],
      "metadata": {
        "id": "LZ4u7hTLk1kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.6. Difusión**\n",
        "a es un tensor unidimensional con forma ([3]).\n",
        "b es un tensor escalar con forma ([1]).\n",
        "Al sumar a y b, PyTorch difunde b para que coincida con la forma de a, lo que resulta en ([1 + 4, 2 + 4, 3 + 4])."
      ],
      "metadata": {
        "id": "mT7438xb9UO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two 1-dimensional tensors\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.tensor([4])\n",
        "\n",
        "# adding a scalar to a vector\n",
        "result = a + b\n",
        "\n",
        "print(\"Result of Broadcasting:\\n\",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAPDFc7kkD7f",
        "outputId": "83707741-c7fa-4a2d-ca3f-e2c78942f7e1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of Broadcasting:\n",
            " tensor([5, 6, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Broadcasting](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics) allows PyTorch to perform element-wise operations on tensors of\n",
        "   - `a` is a 2-dimensional tensor with shape \\([1, 3]\\).\n",
        "   - `b` is a 2-dimensional tensor with shape \\([3, 1]\\).\n",
        "   - When adding `a` and `b`, PyTorch broadcasts both tensors to the common shape \\([3, 3]\\), resulting in:\n",
        "   \n",
        "     \\\n",
        "     \\begin{bmatrix}\n",
        "     1+4 & 2+4 & 3+4 \\\\\n",
        "     1+5 & 2+5 & 3+5 \\\\\n",
        "     1+6 & 2+6 & 3+6 \\\\\n",
        "     \\end{bmatrix}\n",
        "     \\.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e88PB3fnk6p1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La difusión permite a PyTorch realizar operaciones elemento por elemento en tensores de:\n",
        "\n",
        "a es un tensor bidimensional con forma ([1, 3]).\n",
        "\n",
        "b es un tensor bidimensional con forma ([3, 1]).\n",
        "\n",
        "Al sumar a y b, PyTorch difunde ambos tensores a la forma común ([3, 3]), lo que resulta en:"
      ],
      "metadata": {
        "id": "tuJUDpo99ag5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two tensors with shapes (1, 3) and (3, 1)\n",
        "a = torch.tensor([[1, 2, 3]])\n",
        "b = torch.tensor([[4], [5], [6]])\n",
        "\n",
        "# adding tensors of different shapes\n",
        "result = a + b\n",
        "print(\"Shape: \", result.shape)\n",
        "print(\"\\n\")\n",
        "print(\"Result of Broadcasting:\\n\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOoy7pRMk6Kx",
        "outputId": "34bc7f0f-fca9-4108-bf8a-27016f955dd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape:  torch.Size([3, 3])\n",
            "\n",
            "\n",
            "Result of Broadcasting:\n",
            " tensor([[5, 6, 7],\n",
            "        [6, 7, 8],\n",
            "        [7, 8, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkyA9q3_2mkE"
      },
      "source": [
        "## 2.7. CPU v/s GPU Tensor\n",
        "\n",
        "Let’s first see how to create a tensor for GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.7. Tensor de CPU vs. GPU\n",
        "Primero veamos cómo crear un tensor para la GPU."
      ],
      "metadata": {
        "id": "kWOjzCEF9faJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-zGZj6qR2XhM"
      },
      "outputs": [],
      "source": [
        "# Create a tensor for CPU\n",
        "# This will occupy CPU RAM\n",
        "tensor_cpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cpu')\n",
        "\n",
        "# Create a tensor for GPU\n",
        "# This will occupy GPU RAM\n",
        "tensor_gpu = torch.tensor([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]], device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OgEU85m327Oc"
      },
      "source": [
        "Just like tensor creation, the operations performed for CPU and GPU tensors are also different and consume RAM corresponding to the device specified."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al igual que la creación de tensores, las operaciones realizadas para los tensores de CPU y GPU también son diferentes y consumen RAM correspondiente al dispositivo especificado."
      ],
      "metadata": {
        "id": "tOhcWCl49j8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "GCga1AY-2slu"
      },
      "outputs": [],
      "source": [
        "# This uses CPU RAM\n",
        "tensor_cpu = tensor_cpu * 5\n",
        "\n",
        "# This uses GPU RAM\n",
        "# Focus on GPU RAM Consumption\n",
        "tensor_gpu = tensor_gpu * 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcJPGIwG2_Gk"
      },
      "source": [
        "We can move the GPU tensor to CPU and vice versa as shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JjyOE2dG285K"
      },
      "outputs": [],
      "source": [
        "# Move GPU tensor to CPU\n",
        "tensor_gpu_cpu = tensor_gpu.to(device='cpu')\n",
        "\n",
        "# Move CPU tensor to GPU\n",
        "tensor_cpu_gpu = tensor_cpu.to(device='cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znQT1rkq3BHL"
      },
      "source": [
        "# 3. Conclusion\n",
        "\n",
        "\n",
        "In this notebook, we started with constructing simple tensors and manipulating them. Next notebook, we will understand the functionality of Torch Autograd and its role in automatic differentiation and gradient computation.\n",
        "In the upcoming notebooks, we will go deeper into backpropagation and various computer vision tasks such as Classification, Segmentation, Object Detection, and Instance Segmentation. Each notebook will provide a detailed explanation and hands-on examples to help you serve as starter notebooks to master the essential tasks in computer vision."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Conclusión\n",
        "En este cuaderno, comenzamos construyendo tensores simples y manipulándolos. En el siguiente, comprenderemos la funcionalidad de Torch Autograd y su papel en la diferenciación automática y el cálculo de gradientes. En los próximos cuadernos, profundizaremos en la retropropagación y diversas tareas de visión artificial, como clasificación, segmentación, detección de objetos y segmentación de instancias. Cada cuaderno proporcionará una explicación detallada y ejemplos prácticos para ayudarle a dominar las tareas esenciales de la visión artificial."
      ],
      "metadata": {
        "id": "QzOvOpba9o1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: aplicar codigo a otro modelo de tensores en español\n",
        "\n",
        "# Example of applying the code to a different tensor model.\n",
        "# Assuming 'new_tensor_model' is your new tensor data, replace this with your actual data.\n",
        "new_tensor_model = torch.randn(10, 3, 224, 224) # Example: batch of 10 images, 3 channels, 224x224 resolution\n",
        "\n",
        "# Normalize the tensor (similar to what was done with the images)\n",
        "normalized_tensor = new_tensor_model / 255.0  # Assuming pixel values are in the range 0-255\n",
        "print(\"Shape of Normalised Tensor: \", normalized_tensor.shape)\n",
        "print(f\"Normalised Min pixel value: {torch.min(normalized_tensor)} ; Normalised Max pixel value : {torch.max(normalized_tensor)}\")\n",
        "\n",
        "# Perform matrix multiplication (example operation, replace with your desired operation)\n",
        "\n",
        "# Assuming 'weights' are the weights for matrix multiplication, define or load them.\n",
        "weights = torch.randn(3, 3, 3, 3) # Example weights\n",
        "\n",
        "# Check for compatibility, adjust weights dimensions if needed\n",
        "# Example: if your tensor model has different channel number\n",
        "\n",
        "# Perform the operation\n",
        "result = torch.nn.functional.conv2d(normalized_tensor, weights) # Example convolution\n",
        "\n",
        "print(\"Result of Operation:\\n\", result.shape)\n",
        "\n",
        "\n",
        "# Further operations and adaptations will depend on your specific task.\n",
        "\n"
      ],
      "metadata": {
        "id": "U-xo5g-msrfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aef57a6-1002-4d17-93c8-dc05ab768e14"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Normalised Tensor:  torch.Size([10, 3, 224, 224])\n",
            "Normalised Min pixel value: -0.01875005103647709 ; Normalised Max pixel value : 0.0194410290569067\n",
            "Result of Operation:\n",
            " torch.Size([10, 3, 222, 222])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: codigo para aplicar transformers al modelo de imagen en español\n",
        "\n",
        "# Install transformers library\n",
        "!pip install transformers\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Assuming you have a pre-trained model for image classification in Spanish\n",
        "# Replace 'your-model-name' with the actual name of the model, for example: 'google/vit-base-patch16-224'\n",
        "# You can explore Spanish-specific models on Hugging Face's model hub\n",
        "classifier = pipeline(\"image-classification\", model=\"google/vit-base-patch16-224\", device=0 if torch.cuda.is_available() else -1) # Use GPU if available\n",
        "\n",
        "# Load and preprocess your image (example)\n",
        "image_path = \"mnist_0.jpg\"  # Replace with your image path\n",
        "# Ensure the image is in a format compatible with your model.\n",
        "# If your model expects different preprocessing steps, adjust them here.\n",
        "\n",
        "try:\n",
        "  results = classifier(image_path)\n",
        "  print(results)\n",
        "except Exception as e:\n",
        "  print(f\"Error during image classification: {e}\")\n",
        "\n",
        "# Example using the model for another image\n",
        "# ... (Load and preprocess a new image)\n",
        "\n",
        "#try:\n",
        "#  results = classifier(new_image_path)\n",
        "#  print(results)\n",
        "#except Exception as e:\n",
        "#  print(f\"Error during image classification: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480,
          "referenced_widgets": [
            "922af38f59e944ba92e302b460b9cb35",
            "fd9a02a57c6e422b8e157bb8b170b76f",
            "44760e55ac964339931415d262cc6b4d",
            "1d690de6f1fa4d19842386d7218a3dfe",
            "8745b23beff143d7b27ea086247b9c4c",
            "bd6683222c53408c9b64ce9a4931b0ff",
            "e5c33d0172234a51b1df0c6ad1906cf7",
            "e3400c274c184dc0846d019f0d3eba5e",
            "5309760ac5b546c5821c6b9b65f64337",
            "3528c5da3a4c4f80a0d32b6c28468813",
            "48d1adbcad15480b971b028a8ddafa42",
            "cdd6c6c66328418bbbb35851e11d63cf",
            "8c4eaaed6d8745f0ada34eefd98a4e30",
            "702b158604c44b01960858ad71afa26a",
            "b84685363b4c44729679ed7f5db471b1",
            "148df9d1d66342a38eaae78c09149e45",
            "dc0867c399b042fdb956267cd72584fb",
            "20896b8a6ed243d89f2f711a331b9ed4",
            "76a0384d30024b1d923c33a9bcc22f90",
            "b877b10ec4a44b55bb2e941ef7933834",
            "19958593dbbd497a8e9390fac27bdc0a",
            "6d137b0e085a456d9e24d90e750ec240",
            "90caa2fdbd4f4e1280e88aed34dc09ac",
            "776a41bc10b34df18eb27bca3aa75bc7",
            "58aa539419244cb59ef74c44fce4679f",
            "97f8378cfb4f48768f5d453f2839651b",
            "d0701857fe324fb2bdc6ca0e9184494b",
            "239a51f016c0496c8521e682f1a6a1cc",
            "78b40e83c9ad431c8e564d6b452be13e",
            "8eccb782e6ec4647a6f3f08271c7ed81",
            "23fad9887057477fa425b48ee7206017",
            "5514642d453447f0b077cedf78b94e97",
            "31d3d996d84a4751aed695596c1d8045"
          ]
        },
        "id": "6uvnTvb5_ad9",
        "outputId": "a9a419d9-0228-439f-baae-4ade2b08fb88"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "922af38f59e944ba92e302b460b9cb35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdd6c6c66328418bbbb35851e11d63cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90caa2fdbd4f4e1280e88aed34dc09ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'ski mask', 'score': 0.03697305917739868}, {'label': 'binder, ring-binder', 'score': 0.0343455970287323}, {'label': 'safety pin', 'score': 0.03293299302458763}, {'label': 'oil filter', 'score': 0.031178027391433716}, {'label': 'nematode, nematode worm, roundworm', 'score': 0.02436927892267704}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  results = classifier(image_path)\n",
        "  print(results)\n",
        "except Exception as e:\n",
        "  print(f\"Error during image classification: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy4mSuMC-DEs",
        "outputId": "cfe12ddc-b509-4715-92d7-4f4ed1e473db"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'ski mask', 'score': 0.03697305917739868}, {'label': 'binder, ring-binder', 'score': 0.0343455970287323}, {'label': 'safety pin', 'score': 0.03293299302458763}, {'label': 'oil filter', 'score': 0.031178027391433716}, {'label': 'nematode, nematode worm, roundworm', 'score': 0.02436927892267704}]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "922af38f59e944ba92e302b460b9cb35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd9a02a57c6e422b8e157bb8b170b76f",
              "IPY_MODEL_44760e55ac964339931415d262cc6b4d",
              "IPY_MODEL_1d690de6f1fa4d19842386d7218a3dfe"
            ],
            "layout": "IPY_MODEL_8745b23beff143d7b27ea086247b9c4c"
          }
        },
        "fd9a02a57c6e422b8e157bb8b170b76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd6683222c53408c9b64ce9a4931b0ff",
            "placeholder": "​",
            "style": "IPY_MODEL_e5c33d0172234a51b1df0c6ad1906cf7",
            "value": "config.json: 100%"
          }
        },
        "44760e55ac964339931415d262cc6b4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3400c274c184dc0846d019f0d3eba5e",
            "max": 69665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5309760ac5b546c5821c6b9b65f64337",
            "value": 69665
          }
        },
        "1d690de6f1fa4d19842386d7218a3dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3528c5da3a4c4f80a0d32b6c28468813",
            "placeholder": "​",
            "style": "IPY_MODEL_48d1adbcad15480b971b028a8ddafa42",
            "value": " 69.7k/69.7k [00:00&lt;00:00, 1.67MB/s]"
          }
        },
        "8745b23beff143d7b27ea086247b9c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd6683222c53408c9b64ce9a4931b0ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c33d0172234a51b1df0c6ad1906cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3400c274c184dc0846d019f0d3eba5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5309760ac5b546c5821c6b9b65f64337": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3528c5da3a4c4f80a0d32b6c28468813": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d1adbcad15480b971b028a8ddafa42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd6c6c66328418bbbb35851e11d63cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c4eaaed6d8745f0ada34eefd98a4e30",
              "IPY_MODEL_702b158604c44b01960858ad71afa26a",
              "IPY_MODEL_b84685363b4c44729679ed7f5db471b1"
            ],
            "layout": "IPY_MODEL_148df9d1d66342a38eaae78c09149e45"
          }
        },
        "8c4eaaed6d8745f0ada34eefd98a4e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc0867c399b042fdb956267cd72584fb",
            "placeholder": "​",
            "style": "IPY_MODEL_20896b8a6ed243d89f2f711a331b9ed4",
            "value": "model.safetensors: 100%"
          }
        },
        "702b158604c44b01960858ad71afa26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76a0384d30024b1d923c33a9bcc22f90",
            "max": 346293852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b877b10ec4a44b55bb2e941ef7933834",
            "value": 346293852
          }
        },
        "b84685363b4c44729679ed7f5db471b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19958593dbbd497a8e9390fac27bdc0a",
            "placeholder": "​",
            "style": "IPY_MODEL_6d137b0e085a456d9e24d90e750ec240",
            "value": " 346M/346M [00:02&lt;00:00, 195MB/s]"
          }
        },
        "148df9d1d66342a38eaae78c09149e45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc0867c399b042fdb956267cd72584fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20896b8a6ed243d89f2f711a331b9ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76a0384d30024b1d923c33a9bcc22f90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b877b10ec4a44b55bb2e941ef7933834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19958593dbbd497a8e9390fac27bdc0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d137b0e085a456d9e24d90e750ec240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90caa2fdbd4f4e1280e88aed34dc09ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776a41bc10b34df18eb27bca3aa75bc7",
              "IPY_MODEL_58aa539419244cb59ef74c44fce4679f",
              "IPY_MODEL_97f8378cfb4f48768f5d453f2839651b"
            ],
            "layout": "IPY_MODEL_d0701857fe324fb2bdc6ca0e9184494b"
          }
        },
        "776a41bc10b34df18eb27bca3aa75bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239a51f016c0496c8521e682f1a6a1cc",
            "placeholder": "​",
            "style": "IPY_MODEL_78b40e83c9ad431c8e564d6b452be13e",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "58aa539419244cb59ef74c44fce4679f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eccb782e6ec4647a6f3f08271c7ed81",
            "max": 160,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_23fad9887057477fa425b48ee7206017",
            "value": 160
          }
        },
        "97f8378cfb4f48768f5d453f2839651b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5514642d453447f0b077cedf78b94e97",
            "placeholder": "​",
            "style": "IPY_MODEL_31d3d996d84a4751aed695596c1d8045",
            "value": " 160/160 [00:00&lt;00:00, 8.61kB/s]"
          }
        },
        "d0701857fe324fb2bdc6ca0e9184494b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "239a51f016c0496c8521e682f1a6a1cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b40e83c9ad431c8e564d6b452be13e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8eccb782e6ec4647a6f3f08271c7ed81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23fad9887057477fa425b48ee7206017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5514642d453447f0b077cedf78b94e97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d3d996d84a4751aed695596c1d8045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}